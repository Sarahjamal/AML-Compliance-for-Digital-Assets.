{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d5ae7ac",
   "metadata": {},
   "source": [
    "# Data Collection for Defi Data:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb7a9d0",
   "metadata": {},
   "source": [
    "###### Importing transactional data using etherscan api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624c08fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Blockchain Data of an account\n",
    "#importing libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from requests import get\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "#Defining variables\n",
    "\n",
    "API_KEY = \"INSERT YOUR API KEY HERE\"\n",
    "address = \"INSERT YOUR ADDRESS HERE\"\n",
    "BASE_URL = \"https://api.etherscan.io/api\"\n",
    "ETHER_VALUE = 10 ** 18\n",
    "\n",
    "#Importing the balance of an account from ethereum blockchain via API KEY and Address\n",
    "\n",
    "def make_api_url(module, action, address, **kwargs):\n",
    "    url = BASE_URL + f\"?module={module}&action={action}&address={address}&apikey={API_KEY}\"\n",
    "\n",
    "    for key, value in kwargs.items():\n",
    "        url += f\"&{key}={value}\"\n",
    "\n",
    "    return url \n",
    "\n",
    "def get_account_balance(address):\n",
    "    balance_url = make_api_url(\"account\", \"balance\", address, tag=\"latest\")\n",
    "    response = get(balance_url)\n",
    "    data = response.json()\n",
    "\n",
    "    value = int(data[\"result\"]) / ETHER_VALUE\n",
    "    return value\n",
    "eth = get_account_balance(address)\n",
    "print(eth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28950a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the transactions of an account from ethereum blockchain via API KEY and Address\n",
    "\n",
    "def get_transactions(address):\n",
    "    global data\n",
    "    global data2\n",
    "    global data3\n",
    "    \n",
    "#Normal \"Native\" Transactions\n",
    "    transactions_url = make_api_url(\"account\", \"txlist\", address, startblock=0, endblock=99999999, page=1, offset=10000, sort=\"asc\")\n",
    "    response = get(transactions_url)\n",
    "    data = response.json()[\"result\"]\n",
    "    \n",
    "#Internal \"Native\" Transactions\n",
    "\n",
    "    internal_tx_url = make_api_url(\"account\", \"txlistinternal\", address, startblock=0, endblock=99999999, page=1, offset=10000, sort=\"asc\")\n",
    "    response2 = get(internal_tx_url)\n",
    "    data2 = response2.json()[\"result\"]\n",
    "\n",
    "    data.extend(data2)\n",
    "    \n",
    "#ERC20 \"Token\" Transactions \n",
    "\n",
    "    erc20_transactions_url = make_api_url(\"account\", \"tokentx\", address, startblock=0, endblock=99999999, page=1, offset=10000, sort=\"asc\")\n",
    "    response = get(erc20_transactions_url)\n",
    "    data3 = response.json()[\"result\"]\n",
    "    data.extend(data3)\n",
    "    data.sort(key=lambda x: int(x['timeStamp']))\n",
    "    print(data)\n",
    "    \n",
    "get_transactions(address)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e719b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting transactions dictionary into dataframe\n",
    "\n",
    "import csv\n",
    "\n",
    "output_data = data\n",
    "\n",
    "with open('output.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    writer.writerow(output_data[0].keys())  # Write header row\n",
    "\n",
    "    for row in output_data:\n",
    "        writer.writerow(row.values())\n",
    "\n",
    "file.close()\n",
    "\n",
    "df = pd.DataFrame(output_data)\n",
    "\n",
    "df.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2613e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns',None)\n",
    "df = pd.read_csv('F:\\output.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35a45e8",
   "metadata": {},
   "source": [
    "###### Cleaning/ Organizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a41112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting TimeStamp column into string\n",
    "df[\"timeStamp\"] = df[\"timeStamp\"].astype(str)\n",
    "\n",
    "#Converting TimeStamp column from unix format to more simple format\n",
    "df[\"timeStamp\"] = pd.to_datetime(df[\"timeStamp\"],unit = \"s\")\n",
    "\n",
    "df = df.sort_values(by='timeStamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a21242",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new column \"Buy\" based on following condition\n",
    "conditions = [\n",
    "    (df['to'] == 'INSERT YOUR ADDRESS HERE')\n",
    "]\n",
    "results = [df['value']]\n",
    "df['Buy'] = np.select(conditions, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e4f31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new column \"Sell\" based on following condition\n",
    "conditions = [\n",
    "    (df['from'] == 'INSERT YOUR ADDRESS HERE')\n",
    "]\n",
    "results = [df['value']]\n",
    "df['Sell'] = np.select(conditions, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c322ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new column \"Buy Cur.\" based on following condition\n",
    "conditions = [\n",
    "    (df['to'] == 'INSERT YOUR ADDRESS HERE')\n",
    "]\n",
    "results = [df['tokenSymbol']]\n",
    "df['Buy Cur.'] = np.select(conditions, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ac4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new column \"Sell Cur.\" based on following conditi\n",
    "conditions = [\n",
    "    (df['from'] == 'INSERT YOUR ADDRESS HERE')\n",
    "]\n",
    "results = [df['tokenSymbol']]\n",
    "df['Sell Cur.'] = np.select(conditions, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84bfdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling null values with 0\n",
    "df['Buy Cur.'] = df['Buy Cur.'].fillna(0)\n",
    "df['Sell Cur.'] = df['Sell Cur.'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07b562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing 0 with \"ETH\"\n",
    "df['Buy Cur.'] = df['Buy Cur.'].replace(0,'ETH')\n",
    "df['Sell Cur.'] = df['Sell Cur.'].replace(0,'ETH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9925c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating fee amount by multiplying Gas Used with Gas price and diving it by ether value\n",
    "df['Fee'] =  (df[\"gasUsed\"]) * (df[\"gasPrice\"]) / ETHER_VALUE\n",
    "#Defining fee currency\n",
    "df['Fee Cur.'] = \"ETH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec180a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a column of \"Type\" based of following condition:\n",
    "conditions = [\n",
    "    (df['Buy'] == df['Sell']),\n",
    "    (df['from'] == 'INSERT YOUR ADDRESS HERE'),\n",
    "    (df['to'] == 'INSERT YOUR ADDRESS HERE')\n",
    "]\n",
    "results = [\"Other Fees\",\"Deposit\",\"Withdrawal\"]\n",
    "df['Type'] = np.select(conditions, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2794bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"timeStamp\": \"Date\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73194c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Exchange'] = \"ETH wallet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd08d113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleing extra columns\n",
    "df = df.drop([\"blockNumber\", \"hash\", \"nonce\", \"blockHash\", \"transactionIndex\", \"value\", \"gas\", \"gasPrice\", \"isError\", \"txreceipt_status\", \"input\",\"contractAddress\",\"cumulativeGasUsed\", \"gasUsed\" ,\"confirmations\", \"methodId\", \"functionName\", \"tokenName\", \"tokenSymbol\", \"tokenDecimal\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c78ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reindexing\n",
    "df = df.reindex(columns=[\"Type\",\"Buy\",\"Buy Cur.\",\"Sell\",\"Sell Cur.\",\"Fee\",\"Fee Cur.\",\"to\",\"from\",\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0131663",
   "metadata": {},
   "source": [
    "# Importing Cefi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865034f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing CEFI Data\n",
    "df_cefi = pd.read_excel(r'F:\\act_cefidata_11.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9968d74",
   "metadata": {},
   "source": [
    "# Merging Defi and Cefi Datasets into one dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c951f5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining both data sets\n",
    "BIGDATA = pd.concat([df, df_cefi])\n",
    "BIGDATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa73f64",
   "metadata": {},
   "source": [
    "### Cleaning and organizing combines dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6aecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping useless columns\n",
    "df = df.drop([\"Group\", \"Comment\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da17514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c2f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting \"Date\" column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9962403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting values\n",
    "df = df.sort_values('Date')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029874b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering Data\n",
    "# Define the list of values you want to keep in the \"Buy Cur.\" and \"Sell Cur.\" columns\n",
    "desired_values = ['ETH', 'USDT', 'BTC', 'OMG', 'USD', 'USDC', 'ENG', 'CRV', 'REN', 'USDC', 'XZC',\n",
    "                  'YFI', 'RDN', 'BNB', 'XLM', 'GTO', 'CND', 'XMR', 'ICX', 'EOS', 'MKR', 'WPR']\n",
    "\n",
    "# Create boolean masks for rows with valid values in \"Buy Cur.\" or \"Sell Cur.\" columns\n",
    "valid_buy_cur = df['Buy Cur.'].isin(desired_values)\n",
    "valid_sell_cur = df['Sell Cur.'].isin(desired_values)\n",
    "\n",
    "# Filter the DataFrame to keep rows with desired currencies in both columns or if one column is NaN\n",
    "df2 = df[(valid_buy_cur & valid_sell_cur) | (valid_buy_cur & df['Sell Cur.'].isna()) | (valid_sell_cur & df['Buy Cur.'].isna())]\n",
    "\n",
    "# Reset the index, but keep the existing index as a new column\n",
    "df2 = df2.reset_index(drop=False)\n",
    "\n",
    "# Print the filtered dataset\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018e61b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking unique values in columns:\n",
    "for column in df2.columns:\n",
    "    unique_values = df2[column].unique()\n",
    "    print(f\"Unique values in column '{column}':\")\n",
    "    print(unique_values)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e51dbd3",
   "metadata": {},
   "source": [
    "# Accounting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298ee202",
   "metadata": {},
   "source": [
    "### Importing OHLCV Data for each currency for the given time period using Binance api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d7e3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "\n",
    "# Create an instance of the Binance exchange\n",
    "exchange = ccxt.binance()\n",
    "exchange.timeout = 30000\n",
    "# Define the symbols for the cryptocurrencies\n",
    "symbols = ['CRV/USDT', 'XMR/USDT', 'NEO/USDT', 'BTC/USDT', 'BNB/USDT', 'MTL/USDT', 'ZRX/USDT', 'YFI/USDT', 'ICX/USDT', 'EOS/USDT', 'AION/USDT', 'XLM/USDT', 'OMG/USDT', 'XZC/USDT', 'ETH/USDT', 'REN/USDT', 'LTC/USDT', 'HOT/USDT', 'MKR/USDT', 'GTO/USDT']\n",
    "\n",
    "# Define the date range\n",
    "start_date = pd.to_datetime('15 January, 2018')\n",
    "end_date = pd.to_datetime('4 December, 2023')\n",
    "\n",
    "# Define the interval for fetching data (1 day)\n",
    "interval = 86400 * 1000  # 1 day in milliseconds\n",
    "\n",
    "# Fetch the historical rates for each symbol\n",
    "dfs = []\n",
    "for symbol in symbols:\n",
    "    all_rates = []\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        start_timestamp = int(current_date.timestamp() * 1000)\n",
    "        end_timestamp = int((current_date + pd.DateOffset(days=1)).timestamp() * 1000)\n",
    "        rates = exchange.fetch_ohlcv(symbol, timeframe='1d', since=start_timestamp, limit=1000)\n",
    "        all_rates.extend(rates)\n",
    "        current_date += pd.DateOffset(days=1)\n",
    "\n",
    "    symbol_df = pd.DataFrame(all_rates, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    symbol_df['date'] = pd.to_datetime(symbol_df['timestamp'], unit='ms')\n",
    "    symbol_df.set_index('date', inplace=True)\n",
    "    symbol_df.drop(columns=['timestamp'], inplace=True)\n",
    "    symbol_df.columns = [symbol.replace('/', '_') + '_' + column.lower() for column in symbol_df.columns]\n",
    "\n",
    "    # Drop duplicates based on the 'date' column\n",
    "    symbol_df = symbol_df[~symbol_df.index.duplicated(keep='first')]\n",
    "\n",
    "    dfs.append(symbol_df)\n",
    "\n",
    "# Merge the individual DataFrames into a single DataFrame\n",
    "merged_df = pd.concat(dfs, axis=1)\n",
    "\n",
    "# Print the merged DataFrame\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f110e2",
   "metadata": {},
   "source": [
    "### Importing today's rate for each currency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd945304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import datetime\n",
    "\n",
    "# Initialize the Binance exchange instance\n",
    "exchange = ccxt.binance({\n",
    "    'rateLimit': 1200,  # Adjust the rate limit as needed\n",
    "    'enableRateLimit': True,\n",
    "})\n",
    "\n",
    "# Load the Binance markets\n",
    "markets = exchange.load_markets()\n",
    "\n",
    "# List of trading pairs\n",
    "symbols = ['CRV/USDT', 'XMR/USDT', 'NEO/USDT', 'BTC/USDT', 'BNB/USDT', 'MTL/USDT', 'ZRX/USDT', 'YFI/USDT', 'ICX/USDT', 'EOS/USDT', 'AION/USDT', 'XLM/USDT', 'OMG/USDT', 'XZC/USDT', 'ETH/USDT', 'REN/USDT', 'LTC/USDT', 'HOT/USDT', 'MKR/USDT', 'GTO/USDT']\n",
    "\n",
    "# Specify the date for which you want to retrieve the closing prices\n",
    "target_date = datetime.datetime(2023, 8, 7)\n",
    "\n",
    "closing_prices = {}\n",
    "\n",
    "for symbol in symbols:\n",
    "    if symbol in markets:\n",
    "        ccxt_symbol = markets[symbol]['symbol']\n",
    "        \n",
    "        # Fetch historical OHLCV data\n",
    "        ohlcv = exchange.fetch_ohlcv(ccxt_symbol, '1d', since=int(target_date.timestamp()) * 1000)\n",
    "        \n",
    "        if len(ohlcv) > 0:\n",
    "            closing_price = ohlcv[0][4]  # Closing price is at index 4\n",
    "            closing_prices[symbol] = closing_price\n",
    "    else:\n",
    "        print(f\"Symbol {symbol} not found in markets.\")\n",
    "\n",
    "# Create variables dynamically for each trading pair's closing price\n",
    "for symbol, price in closing_prices.items():\n",
    "    # Remove special characters to create a valid variable name\n",
    "    variable_name = symbol.replace('/', '_').replace('-', '_').replace('.', '_')\n",
    "    globals()[variable_name] = price\n",
    "\n",
    "# Print the closing prices\n",
    "for symbol, price in closing_prices.items():\n",
    "    print(f\"{symbol}: {price}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e31e45f",
   "metadata": {},
   "source": [
    "### Calculating Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd64a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of columns ending with '_close'\n",
    "close_columns = [col for col in merged_df.columns if col.endswith('_close')]\n",
    "\n",
    "# Include the 'date' column along with the 'close' columns\n",
    "selected_columns = ['date'] + close_columns\n",
    "\n",
    "# Create a new DataFrame with only the selected columns\n",
    "df_rates = merged_df[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed10a720",
   "metadata": {},
   "source": [
    "###### Merging rates with our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = df2.merge(df_rates, on='Date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c14b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary mapping 'Buy Cur.' values to their corresponding close column names\n",
    "cur_to_close = {\n",
    "    'USDT': None,\n",
    "    'USDC': None,\n",
    "    'CRV': 'CRV_USDT_close',\n",
    "    'XMR': 'XMR_USDT_close',\n",
    "    'NEO': 'NEO_USDT_close',\n",
    "    'BTC': 'BTC_USDT_close',\n",
    "    'BNB': 'BNB_USDT_close',\n",
    "    'MTL': 'MTL_USDT_close',\n",
    "    'ZRX': 'ZRX_USDT_close',\n",
    "    'YFI': 'YFI_USDT_close',\n",
    "    'ICX': 'ICX_USDT_close',\n",
    "    'EOS': 'EOS_USDT_close',\n",
    "    'AION': 'AION_USDT_close',\n",
    "    'XLM': 'XLM_USDT_close',\n",
    "    'OMG': 'OMG_USDT_close',\n",
    "    'XZC': 'XZC_USDT_close',\n",
    "    'ETH': 'ETH_USDT_close',\n",
    "    'REN': 'REN_USDT_close',\n",
    "    'LTC': 'LTC_USDT_close',\n",
    "    'HOT': 'HOT_USDT_close',\n",
    "    'MKR': 'MKR_USDT_close',\n",
    "    'GTO': 'GTO_USDT_close'\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store the conditions and results for the np.select function\n",
    "conditions = []\n",
    "results = []\n",
    "\n",
    "# Loop through the 'Buy Cur.' values and construct conditions and results dynamically\n",
    "for cur, close_column in cur_to_close.items():\n",
    "    condition = (merged_df['Buy Cur.'] == cur)\n",
    "    conditions.append(condition)\n",
    "    \n",
    "    if close_column is not None:\n",
    "        result = merged_df['Buy'] * merged_df[close_column]\n",
    "    else:\n",
    "        result = 1\n",
    "    results.append(result)\n",
    "\n",
    "# Use np.select to create the 'Buy Rate' column based on the conditions and results\n",
    "merged_df['Buy Rate'] = np.select(conditions, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35a7a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary mapping 'Buy Cur.' values to their corresponding close column names\n",
    "cur_to_close = {\n",
    "    'USDT': None,\n",
    "    'USDC': None,\n",
    "    'CRV': 'CRV_USDT_close',\n",
    "    'XMR': 'XMR_USDT_close',\n",
    "    'NEO': 'NEO_USDT_close',\n",
    "    'BTC': 'BTC_USDT_close',\n",
    "    'BNB': 'BNB_USDT_close',\n",
    "    'MTL': 'MTL_USDT_close',\n",
    "    'ZRX': 'ZRX_USDT_close',\n",
    "    'YFI': 'YFI_USDT_close',\n",
    "    'ICX': 'ICX_USDT_close',\n",
    "    'EOS': 'EOS_USDT_close',\n",
    "    'AION': 'AION_USDT_close',\n",
    "    'XLM': 'XLM_USDT_close',\n",
    "    'OMG': 'OMG_USDT_close',\n",
    "    'XZC': 'XZC_USDT_close',\n",
    "    'ETH': 'ETH_USDT_close',\n",
    "    'REN': 'REN_USDT_close',\n",
    "    'LTC': 'LTC_USDT_close',\n",
    "    'HOT': 'HOT_USDT_close',\n",
    "    'MKR': 'MKR_USDT_close',\n",
    "    'GTO': 'GTO_USDT_close'\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store the conditions and results for the np.select function\n",
    "conditions = []\n",
    "results = []\n",
    "\n",
    "# Loop through the 'Buy Cur.' values and construct conditions and results dynamically\n",
    "for cur, close_column in cur_to_close.items():\n",
    "    condition = (merged_df['Sell Cur.'] == cur)\n",
    "    conditions.append(condition)\n",
    "    \n",
    "    if close_column is not None:\n",
    "        result = merged_df['Sell'] * merged_df[close_column]\n",
    "    else:\n",
    "        result = 1\n",
    "    results.append(result)\n",
    "\n",
    "# Use np.select to create the 'Buy Rate' column based on the conditions and results\n",
    "merged_df['Sell Rate'] = np.select(conditions, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dd854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column for Fair market value of withdrawal\n",
    "merged_df['FMV Withdrawal'] = pd.NaT\n",
    "\n",
    "# Set the values in 'FMV Withdrawal' column based on the condition\n",
    "withdrawal_condition = (merged_df['Type'] == 'Withdrawal') | (merged_df['Type'] == 'Expense (non taxable)')\n",
    "merged_df.loc[withdrawal_condition, 'FMV Withdrawal'] = merged_df.loc[withdrawal_condition, 'Sell Rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae0b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column for Fair market value of deposit\n",
    "merged_df['FMV Deposit'] = pd.NaT\n",
    "\n",
    "# Set the values in 'FMV Deposit' column based on the condition\n",
    "deposit_condition = (merged_df['Type'] == 'Deposit') | (merged_df['Type'] == 'Income (non taxable)')\n",
    "merged_df.loc[deposit_condition, 'FMV Deposit'] = merged_df.loc[deposit_condition, 'Sell Rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee90587",
   "metadata": {},
   "source": [
    "### Calculating Capital Gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706c12e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating capital gains on Type\n",
    "currencies = ['USDT', 'USDC','CRV', 'XMR', 'NEO', 'BTC', 'BNB', 'MTL', 'ZRX', 'YFI','ICX', 'EOS', 'AION', 'XLM', 'OMG', 'XZC', 'ETH', 'REN','LTC', 'HOT', 'MKR', 'GTO']\n",
    "capital_gains = []\n",
    "\n",
    "for currency in currencies:\n",
    "    # Filter the dataset based on the specified conditions\n",
    "    sell_df = merged_df[(merged_df['Type'] == 'Trade') & (merged_df['Buy Cur.'] == currency)]\n",
    "    buy_df = merged_df[(merged_df['Type'] == 'Trade') & (merged_df['Sell Cur.'] == currency)]\n",
    "    \n",
    "    # Calculate the sum of 'Sell Rate' and 'Buy Rate' from the filtered datasets\n",
    "    sell_sum = sell_df['Sell Rate'].sum()\n",
    "    buy_sum = buy_df['Buy Rate'].sum()\n",
    "    \n",
    "    # Calculate the capital gain\n",
    "    capital_gain = buy_sum - sell_sum\n",
    "    capital_gains.append(capital_gain)\n",
    "    \n",
    "    # Print the capital gain for each currency\n",
    "    print(f\"T_CGT_{currency}:\", capital_gain)\n",
    "\n",
    "# Create a dictionary with the variable names and their corresponding values\n",
    "data = {\n",
    "    'Token': [f\"T_CGT_{currency}\" for currency in currencies],\n",
    "    'Capital Gain': capital_gains\n",
    "}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "df_cgt = pd.DataFrame(data)\n",
    "\n",
    "# Calculate the sum of 'Capital Gain'\n",
    "T_TCGT = df_cgt['Capital Gain'].sum()\n",
    "\n",
    "# Add the sum as a new row in the DataFrame\n",
    "df_cgt.loc['Total'] = ['T_TCGT', T_TCGT]\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_cgt)\n",
    "\n",
    "# Store the TCGT as a separate variable\n",
    "T_TCGT_variable = T_TCGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46241d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating capital gains on OTHER FEE\n",
    "# Assuming you have a DataFrame named merged_df\n",
    "# Define the list of values you want to keep in the \"Buy Cur.\" and \"Sell Cur.\" columns\n",
    "desired_values = ['USDT', 'USDC','CRV', 'XMR', 'NEO', 'BTC', 'BNB', 'MTL', 'ZRX', 'YFI','ICX', 'EOS', 'AION', 'XLM', 'OMG', 'XZC', 'ETH', 'REN','LTC', 'HOT', 'MKR', 'GTO']\n",
    "\n",
    "# Define the conditions for filtering\n",
    "filter_conditions = (merged_df['Type'].isin(['Other Fees', 'Other Fee']))\n",
    "\n",
    "# Initialize dictionaries to store cost basis and proceeds for each currency\n",
    "cost_basis = {}\n",
    "proceeds = {}\n",
    "\n",
    "# Calculate cost basis and proceeds for each currency in desired_values\n",
    "for currency in desired_values:\n",
    "    filtered_buy_df = merged_df.loc[filter_conditions & (merged_df['Buy Cur.'] == currency)]\n",
    "    filtered_sell_df = merged_df.loc[filter_conditions & (merged_df['Sell Cur.'] == currency)]\n",
    "\n",
    "    cost_basis[currency] = filtered_sell_df['Sell Rate'].sum()\n",
    "    proceeds[currency] = filtered_buy_df['Buy Rate'].sum()\n",
    "\n",
    "# Calculate total capital gains on Other fees for all currencies\n",
    "O_TCGT_total = sum(proceeds.values()) - sum(cost_basis.values())\n",
    "\n",
    "# Print individual cost basis, proceeds, and total capital gains for each currency\n",
    "for currency in desired_values:\n",
    "    print(f\"O_CB_{currency}:\", cost_basis[currency])\n",
    "    print(f\"O_PR_{currency}:\", proceeds[currency])\n",
    "\n",
    "print(\"O_TCGT_total:\", O_TCGT_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9541bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating capital gains on Staking\n",
    "# Assuming you have a DataFrame named merged_df\n",
    "\n",
    "# Define the list of currencies for staking\n",
    "staking_currencies = ['USDT', 'USDC', 'CRV', 'XMR', 'NEO', 'BTC', 'BNB', 'MTL', 'ZRX', 'YFI', 'ICX', 'EOS','AION', 'XLM', 'OMG', 'XZC', 'ETH', 'REN', 'LTC', 'HOT', 'MKR', 'GTO']\n",
    "\n",
    "# Remove duplicates (if any) from the staking_currencies list\n",
    "staking_currencies = list(set(staking_currencies))\n",
    "\n",
    "# Initialize dictionaries to store proceeds and capital gains for each staking currency\n",
    "staking_proceeds = {}\n",
    "staking_capital_gains = {}\n",
    "S_TCGT = 0\n",
    "\n",
    "# Calculate proceeds and capital gains on staking\n",
    "for currency in staking_currencies:\n",
    "    staking_df = merged_df[(merged_df['Type'] == 'Staking') & (merged_df['Buy Cur.'] == currency)]\n",
    "    staking_proceeds[currency] = staking_df['Buy Rate'].sum()\n",
    "    staking_capital_gains[currency] = staking_proceeds[currency] - staking_df['Sell Rate'].sum()  # Corrected calculation\n",
    "    print(f\"S_PR_{currency}: {staking_proceeds[currency]}\")\n",
    "    print(f\"S_CGT_{currency}: {staking_capital_gains[currency]}\")\n",
    "    \n",
    "    S_TCGT += staking_capital_gains[currency]\n",
    "\n",
    "print(\"S_TCGT:\", S_TCGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0eed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating capital gains on 'Derivatives / Futures Profit / Futures Loss',\n",
    "# Calculate sum of \"Buy\" column for \"Derivatives / Futures Profit\" type\n",
    "derivatives_profit_sum = merged_df.loc[merged_df['Type'] == 'Derivatives / Futures Profit', 'Buy'].sum()\n",
    "\n",
    "# Calculate sum of \"Sell\" column for \"Derivatives / Futures Loss\" type\n",
    "derivatives_loss_sum = merged_df.loc[merged_df['Type'] == 'Derivatives / Futures Loss', 'Sell'].sum()\n",
    "\n",
    "# Calculate D_TCGT (Derivatives / Futures Total Capital Gains)\n",
    "D_TCGT = derivatives_profit_sum - derivatives_loss_sum  \n",
    "\n",
    "# Print the result\n",
    "print(\"D_TCGT:\", D_TCGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec1b8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating capital gains on LP Rewards\n",
    "# Assuming you have a DataFrame named merged_df\n",
    "\n",
    "# Define the list of currencies for LP Rewards\n",
    "lp_rewards_currencies = ['USDT', 'USDC', 'CRV', 'XMR', 'NEO', 'BTC', 'BNB', 'MTL', 'ZRX', 'YFI', 'ICX', 'EOS','AION', 'XLM', 'OMG', 'XZC', 'ETH', 'REN', 'LTC', 'HOT', 'MKR', 'GTO']\n",
    "\n",
    "# Remove duplicates (if any) from the lp_rewards_currencies list\n",
    "lp_rewards_currencies = list(set(lp_rewards_currencies))\n",
    "\n",
    "# Initialize dictionaries to store proceeds and capital gains for each LP Rewards currency\n",
    "lp_rewards_proceeds = {}\n",
    "lp_rewards_capital_gains = {}\n",
    "LP_TCGT = 0\n",
    "\n",
    "# Calculate proceeds and capital gains on LP Rewards\n",
    "for currency in lp_rewards_currencies:\n",
    "    lp_rewards_df = merged_df[(merged_df['Type'] == 'LP Rewards') & (merged_df['Buy Cur.'] == currency)]\n",
    "    lp_rewards_proceeds[currency] = lp_rewards_df['Buy Rate'].sum()\n",
    "    lp_rewards_capital_gains[currency] = lp_rewards_proceeds[currency] - lp_rewards_df['Sell Rate'].sum()\n",
    "    print(f\"LP_PR_{currency}: {lp_rewards_proceeds[currency]}\")\n",
    "    print(f\"LP_CGT_{currency}: {lp_rewards_capital_gains[currency]}\")\n",
    "    \n",
    "    LP_TCGT += lp_rewards_capital_gains[currency]\n",
    "\n",
    "print(\"LP_TCGT:\", LP_TCGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd00fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating capital gains on Other Income\n",
    "# Assuming you have a DataFrame named merged_df\n",
    "\n",
    "# Define the list of currencies for Other Income\n",
    "other_income_currencies = ['USDT', 'USDC', 'CRV', 'XMR', 'NEO', 'BTC', 'BNB', 'MTL', 'ZRX', 'YFI', 'ICX', 'EOS',\n",
    "                          'AION', 'XLM', 'OMG', 'XZC', 'ETH', 'REN', 'LTC', 'HOT', 'MKR', 'GTO']\n",
    "\n",
    "# Remove duplicates (if any) from the other_income_currencies list\n",
    "other_income_currencies = list(set(other_income_currencies))\n",
    "\n",
    "# Initialize dictionaries to store proceeds and capital gains for each Other Income currency\n",
    "other_income_proceeds = {}\n",
    "other_income_capital_gains = {}\n",
    "OI_TCGT = 0\n",
    "\n",
    "# Calculate proceeds and capital gains on Other Income\n",
    "for currency in other_income_currencies:\n",
    "    other_income_df = merged_df[(merged_df['Type'] == 'Other Income') & (merged_df['Buy Cur.'] == currency)]\n",
    "    other_income_proceeds[currency] = other_income_df['Buy Rate'].sum()\n",
    "    other_income_capital_gains[currency] = other_income_proceeds[currency] - other_income_df['Sell Rate'].sum()\n",
    "    print(f\"OI_PR_{currency}: {other_income_proceeds[currency]}\")\n",
    "    print(f\"OI_CGT_{currency}: {other_income_capital_gains[currency]}\")\n",
    "    \n",
    "    OI_TCGT += other_income_capital_gains[currency]\n",
    "\n",
    "print(\"OI_TCGT:\", OI_TCGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa8f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating capital gains on Other Expense\n",
    "# Calculating capital losses on Other Expense\n",
    "# Assuming you have a DataFrame named merged_df\n",
    "\n",
    "# Define the list of currencies for Other Expense\n",
    "other_expense_currencies = ['USDT', 'USDC', 'CRV', 'XMR', 'NEO', 'BTC', 'BNB', 'MTL', 'ZRX', 'YFI', 'ICX', 'EOS','AION', 'XLM', 'OMG', 'XZC', 'ETH', 'REN', 'LTC', 'HOT', 'MKR', 'GTO']\n",
    "\n",
    "# Remove duplicates (if any) from the other_expense_currencies list\n",
    "other_expense_currencies = list(set(other_expense_currencies))\n",
    "\n",
    "# Initialize the variable to store the total capital losses for Other Expense\n",
    "OE_TCGT = 0\n",
    "\n",
    "# Calculate capital losses on Other Expense\n",
    "for currency in other_expense_currencies:\n",
    "    other_expense_df = merged_df[(merged_df['Type'] == 'Other Expense') & (merged_df['Sell Cur.'] == currency)]\n",
    "    capital_losses = -(other_expense_df['Sell Rate'].sum())  # Multiply with -1 to account for losses\n",
    "    print(f\"OE_CGT_{currency}: {capital_losses}\")\n",
    "    \n",
    "    OE_TCGT += capital_losses\n",
    "\n",
    "print(\"OE_TCGT:\", OE_TCGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f36b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating capital losses on Donation\n",
    "# Assuming you have a DataFrame named merged_df\n",
    "\n",
    "# Define the list of currencies for Donation\n",
    "donation_currencies = ['USDT', 'USDC', 'CRV', 'XMR', 'NEO', 'BTC', 'BNB', 'MTL', 'ZRX', 'YFI', 'ICX', 'EOS','AION', 'XLM', 'OMG', 'XZC', 'ETH', 'REN', 'LTC', 'HOT', 'MKR', 'GTO']\n",
    "\n",
    "# Remove duplicates (if any) from the donation_currencies list\n",
    "donation_currencies = list(set(donation_currencies))\n",
    "\n",
    "# Initialize the variable to store the total capital losses for Donation\n",
    "DN_TCGT = 0\n",
    "\n",
    "# Calculate capital losses on Donation\n",
    "for currency in donation_currencies:\n",
    "    donation_df = merged_df[(merged_df['Type'] == 'Donation') & (merged_df['Sell Cur.'] == currency)]\n",
    "    capital_losses = -(donation_df['Sell Rate'].sum())  # Multiply with -1 to account for losses\n",
    "    print(f\"DN_CGT_{currency}: {capital_losses}\")\n",
    "    \n",
    "    DN_TCGT += capital_losses\n",
    "\n",
    "print(\"DN_TCGT:\", DN_TCGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec36d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating capital losses on Spend\n",
    "# Assuming you have a DataFrame named merged_df\n",
    "\n",
    "# Define the list of currencies for Spend\n",
    "spend_currencies = ['USDT', 'USDC', 'CRV', 'XMR', 'NEO', 'BTC', 'BNB', 'MTL', 'ZRX', 'YFI', 'ICX', 'EOS','AION', 'XLM', 'OMG', 'XZC', 'ETH', 'REN', 'LTC', 'HOT', 'MKR', 'GTO']\n",
    "\n",
    "# Remove duplicates (if any) from the spend_currencies list\n",
    "spend_currencies = list(set(spend_currencies))\n",
    "\n",
    "# Initialize the variable to store the total capital losses for Spend\n",
    "SP_TCGT = 0\n",
    "\n",
    "# Calculate capital losses on Spend\n",
    "for currency in spend_currencies:\n",
    "    spend_df = merged_df[(merged_df['Type'] == 'Spend') & (merged_df['Sell Cur.'] == currency)]\n",
    "    capital_losses = -(spend_df['Sell Rate'].sum())  # Multiply with -1 to account for losses\n",
    "    print(f\"SP_CGT_{currency}: {capital_losses}\")\n",
    "    \n",
    "    SP_TCGT += capital_losses\n",
    "\n",
    "print(\"SP_TCGT:\", SP_TCGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6471afaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating capital gains on Airdrop\n",
    "# Assuming you have a DataFrame named merged_df\n",
    "\n",
    "# Define the list of currencies for Airdrop\n",
    "airdrop_currencies = ['USDT', 'USDC', 'CRV', 'XMR', 'NEO', 'BTC', 'BNB', 'MTL', 'ZRX', 'YFI', 'ICX', 'EOS','AION', 'XLM', 'OMG', 'XZC', 'ETH', 'REN', 'LTC', 'HOT', 'MKR', 'GTO']\n",
    "\n",
    "# Remove duplicates (if any) from the airdrop_currencies list\n",
    "airdrop_currencies = list(set(airdrop_currencies))\n",
    "\n",
    "# Initialize dictionaries to store proceeds and capital gains for each airdrop currency\n",
    "airdrop_proceeds = {}\n",
    "airdrop_capital_gains = {}\n",
    "AI_TCGT = 0\n",
    "\n",
    "# Calculate proceeds and capital gains on Airdrop\n",
    "for currency in airdrop_currencies:\n",
    "    airdrop_df = merged_df[(merged_df['Type'] == 'Airdrop') & (merged_df['Buy Cur.'] == currency)]\n",
    "    airdrop_proceeds[currency] = airdrop_df['Buy Rate'].sum()\n",
    "    airdrop_capital_gains[currency] = airdrop_proceeds[currency] - airdrop_df['Sell Rate'].sum()\n",
    "    print(f\"AI_PR_{currency}: {airdrop_proceeds[currency]}\")\n",
    "    print(f\"AI_CGT_{currency}: {airdrop_capital_gains[currency]}\")\n",
    "    \n",
    "    AI_TCGT += airdrop_capital_gains[currency]\n",
    "\n",
    "print(\"AI_TCGT:\", AI_TCGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8effd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating capital gains on Reward / Bonus\n",
    "# Assuming you have a DataFrame named merged_df\n",
    "\n",
    "# Define the list of currencies for Reward / Bonus\n",
    "reward_bonus_currencies = ['USDT', 'USDC', 'CRV', 'XMR', 'NEO', 'BTC', 'BNB', 'MTL', 'ZRX', 'YFI', 'ICX', 'EOS',\n",
    "                           'AION', 'XLM', 'OMG', 'XZC', 'ETH', 'REN', 'LTC', 'HOT', 'MKR', 'GTO']\n",
    "\n",
    "# Remove duplicates (if any) from the reward_bonus_currencies list\n",
    "reward_bonus_currencies = list(set(reward_bonus_currencies))\n",
    "\n",
    "# Initialize dictionaries to store proceeds and capital gains for each Reward / Bonus currency\n",
    "reward_bonus_proceeds = {}\n",
    "reward_bonus_capital_gains = {}\n",
    "RB_TCGT = 0\n",
    "\n",
    "# Calculate proceeds and capital gains on Reward / Bonus\n",
    "for currency in reward_bonus_currencies:\n",
    "    reward_bonus_df = merged_df[(merged_df['Type'] == 'Reward / Bonus') & (merged_df['Buy Cur.'] == currency)]\n",
    "    reward_bonus_proceeds[currency] = reward_bonus_df['Buy Rate'].sum()\n",
    "    reward_bonus_capital_gains[currency] = reward_bonus_proceeds[currency] - reward_bonus_df['Sell Rate'].sum()\n",
    "    print(f\"RB_PR_{currency}: {reward_bonus_proceeds[currency]}\")\n",
    "    print(f\"RB_CGT_{currency}: {reward_bonus_capital_gains[currency]}\")\n",
    "    \n",
    "    RB_TCGT += reward_bonus_capital_gains[currency]\n",
    "\n",
    "print(\"RB_TCGT:\", RB_TCGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd784ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total capital gains\n",
    "TCGT = T_TCGT + O_TCGT_total + S_TCGT + D_TCGT + LP_TCGT + OI_TCGT + OE_TCGT + DN_TCGT + SP_TCGT + AI_TCGT + RB_TCGT\n",
    "TCGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a127a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tax on Capital gains (assuming tax is 30%)\n",
    "PER_TCGT = 0.3 * TCGT\n",
    "PER_TCGT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06750431",
   "metadata": {},
   "source": [
    "# Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de665c0",
   "metadata": {},
   "source": [
    "### Volume Based Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb77b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store results\n",
    "results = {}\n",
    "\n",
    "for currency in ['USDT', 'USDC', 'CRV', 'XMR', 'NEO', 'BTC', 'BNB', 'MTL', 'ZRX', 'YFI', 'ICX', 'EOS', 'AION', 'XLM', 'OMG', 'XZC', 'ETH', 'REN', 'LTC', 'HOT', 'MKR', 'GTO']:\n",
    "    # Step 1: Sum all values in \"Sell\" column where \"Sell Cur.\" is the current currency\n",
    "    sell_sum = merged_df.loc[merged_df['Sell Cur.'] == currency, 'Sell'].sum()\n",
    "    \n",
    "    # Step 2: Sum all values in \"Buy\" column where \"Buy Cur.\" is the current currency\n",
    "    buy_sum = merged_df.loc[merged_df['Buy Cur.'] == currency, 'Buy'].sum()\n",
    "    \n",
    "    # Step 3: Calculate the difference between buy_sum and sell_sum\n",
    "    diff = sell_sum - buy_sum  \n",
    "    \n",
    "    # Step 4: Multiply the difference with the appropriate value\n",
    "    if currency in ['USDT', 'USDC']:\n",
    "        result = diff * 1  # Multiply by 1 for USDT and USDC\n",
    "    elif currency + '/USDT' in closing_prices:\n",
    "        result = diff * closing_prices[currency + '/USDT']\n",
    "        results[currency] = result\n",
    "\n",
    "# Calculate the total closing balance\n",
    "closing_balance = sum(results.values())\n",
    "\n",
    "# Print the individual results\n",
    "for currency, result in results.items():\n",
    "    print(f\"{currency}: {result}\")\n",
    "\n",
    "# Print the total closing balance\n",
    "print(f\"Closing Balance: {closing_balance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2637fb01",
   "metadata": {},
   "source": [
    "### Risk Based Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2137bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAKING DATA BASE\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('RISKY_ACCOUNTS.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a087d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'file1.csv' with the path to your first CSV file\n",
    "Risky_CEX = pd.read_csv('Risky_CEX.csv')\n",
    "P2P = pd.read_csv('P2P.csv')\n",
    "Dark_Service = pd.read_csv('Dark_Service.csv')\n",
    "Sanction = pd.read_csv('Sanction.csv')\n",
    "Stolen_Coins = pd.read_csv('Stolen_Coins.csv')\n",
    "Gambling = pd.read_csv('Gambling.csv')\n",
    "Enforcement = pd.read_csv('Enforcement.csv')\n",
    "Scam = pd.read_csv('Scam.csv')\n",
    "Prepaid_Cryptocurrency_Cards = pd.read_csv('Prepaid_Cryptocurrency_Cards.csv')\n",
    "BTC_ATM = pd.read_csv('BTC_ATM.csv')\n",
    "\n",
    "# Create a SQLite database connection\n",
    "conn = sqlite3.connect('my_database.db')  # Replace 'my_database.db' with your desired database name\n",
    "\n",
    "# Replace 'table_name1' with the desired name for the first table in the database\n",
    "Risky_CEX.to_sql('Risky_CEX', conn, index=False, if_exists='replace')\n",
    "# Repeat the process for other CSV files and tables\n",
    "P2P.to_sql('P2P', conn, index=False, if_exists='replace')\n",
    "Dark_Service.to_sql('Dark_Service', conn, index=False, if_exists='replace')\n",
    "Sanction.to_sql('Sanction', conn, index=False, if_exists='replace')\n",
    "Stolen_Coins.to_sql('Stolen_Coins', conn, index=False, if_exists='replace')\n",
    "Gambling.to_sql('Gambling', conn, index=False, if_exists='replace')\n",
    "Enforcement.to_sql('Enforcement', conn, index=False, if_exists='replace')\n",
    "Scam.to_sql('Scam', conn, index=False, if_exists='replace')\n",
    "Prepaid_Cryptocurrency_Cards.to_sql('Prepaid_Cryptocurrency_Cards', conn, index=False, if_exists='replace')\n",
    "BTC_ATM.to_sql('BTC_ATM', conn, index=False, if_exists='replace')\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69ce9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('my_database.db')  # Replace 'my_database.db' with your actual database name\n",
    "# Step 3: Loop through all tables in the database and compare with 'merged_df'\n",
    "tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5f4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING IT AGAINST OUR DATASET\n",
    "import sqlite3\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect('my_database.db')  # Replace 'my_database.db' with your actual database name\n",
    "# Step 3: Loop through all tables in the database and compare with 'merged_df'\n",
    "tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\").fetchall()\n",
    "\n",
    "\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    print(f\"\\nTable Name: {table_name}\")\n",
    "    # Read the table from the database\n",
    "    df_table = pd.read_sql(f\"SELECT * FROM {table_name}\", conn)\n",
    "    print(\"Table Content:\")\n",
    "    print(df_table.head())\n",
    "    # Check for matching values in 'merged_df' and print the table name if there is a match\n",
    "    matching_values = df_table['Accounts'].isin(df['From'])\n",
    "    print(\"Matching Values:\")\n",
    "    print(matching_values)\n",
    "    if matching_values.any():\n",
    "        print(f\"Matching values found in table: {table_name}\")\n",
    "\n",
    "# Step 4: Close the database connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a621c9",
   "metadata": {},
   "source": [
    "### Behavior based Monitoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd237637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR MONTHLY DEPOSIT/WITHDRAWAL\n",
    "# Extract both month and year from the 'Date' column and create a new 'Month' column\n",
    "merged_df['Month'] = merged_df['Date'].dt.to_period('M').astype(str)\n",
    "\n",
    "# Group the data by month and year and calculate the sum of deposits and withdrawals for each month\n",
    "monthly_data = merged_df.groupby(['Month']).agg({\n",
    "    'FMV Withdrawal': 'sum',\n",
    "    'FMV Deposit': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate the difference (Deposit - Withdrawal)\n",
    "monthly_data['Deposit - Withdrawal'] = monthly_data['FMV Deposit'] - monthly_data['FMV Withdrawal']\n",
    "\n",
    "# Print the result\n",
    "print(monthly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98cb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for transactions with 'Buy Cur.' or 'Sell Cur.' as 'USDT' or 'USDC'\n",
    "stablecoin_df = merged_df[(merged_df['Buy Cur.'] == 'USDT') | (merged_df['Buy Cur.'] == 'USDC') |\n",
    "                          (merged_df['Sell Cur.'] == 'USDT') | (merged_df['Sell Cur.'] == 'USDC')]\n",
    "\n",
    "# Calculate the total stablecoin transactions for the entire dataset\n",
    "total_stablecoin_transactions = stablecoin_df.shape[0]\n",
    "\n",
    "# Calculate the total transactions for the entire dataset\n",
    "total_transactions = merged_df.shape[0]\n",
    "\n",
    "# Calculate the overall percentage of stablecoin transactions\n",
    "overall_percentage = (total_stablecoin_transactions / total_transactions) * 100\n",
    "\n",
    "# Group the filtered data by month and year to get the total stablecoin transactions for each month\n",
    "stablecoin_transactions = stablecoin_df.groupby(['Month']).size().reset_index(name='Stablecoin Transactions')\n",
    "\n",
    "# Group the original 'merged_df' DataFrame by month and year to get the total transactions for each month\n",
    "total_transactions_monthly = merged_df.groupby(['Month']).size().reset_index(name='Total Transactions')\n",
    "\n",
    "# Merge the two DataFrames on 'Month' to calculate the percentage\n",
    "result_df = pd.merge(total_transactions_monthly, stablecoin_transactions, on='Month', how='left')\n",
    "\n",
    "# Calculate the monthly percentage of stablecoin transactions\n",
    "result_df['Monthly Percentage'] = (result_df['Stablecoin Transactions'] / result_df['Total Transactions']) * 100\n",
    "\n",
    "# Calculate the total monthly percentage compared to the overall percentage\n",
    "result_df['Total Monthly Percentage'] = (result_df['Monthly Percentage'] / overall_percentage) * 100\n",
    "\n",
    "# Calculate the overall monthly percentage for the entire dataset\n",
    "overall_monthly_percentage = (result_df['Stablecoin Transactions'].sum() / result_df['Total Transactions'].sum()) * 100\n",
    "\n",
    "# Print the result\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40fe4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Movement Of Stablecoins Across Multiple Wallets.\n",
    "# Filter the DataFrame for transactions with 'Buy Cur.' or 'Sell Cur.' as 'USDT' or 'USDC'\n",
    "filtered_df = merged_df[(merged_df['Buy Cur.'] == 'USDT') | (merged_df['Buy Cur.'] == 'USDC') |\n",
    "                        (merged_df['Sell Cur.'] == 'USDT') | (merged_df['Sell Cur.'] == 'USDC')]\n",
    "\n",
    "# Group the filtered data by month and year and calculate the sum of deposits and withdrawals for each month\n",
    "monthly_data = filtered_df.groupby(['Month']).agg({\n",
    "    'FMV Withdrawal': 'sum',\n",
    "    'FMV Deposit': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate the difference (Deposit - Withdrawal)\n",
    "monthly_data['Deposit - Withdrawal'] = monthly_data['FMV Deposit'] - monthly_data['FMV Withdrawal']\n",
    "\n",
    "# Print the result\n",
    "print(monthly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the monthly closing balance\n",
    "monthly_closing_balance = merged_df.groupby('Month').apply(lambda x: (x['Sell Rate'] - x['Buy Rate']).sum()).reset_index(name='Closing Balance')\n",
    "\n",
    "# Print the result\n",
    "print(monthly_closing_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac3bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the yearly closing balance\n",
    "yearly_closing_balance = merged_df.groupby(merged_df['Date'].dt.year)['Sell Rate', 'Buy Rate'].sum()\n",
    "yearly_closing_balance['Closing Balance'] = yearly_closing_balance['Sell Rate'] - yearly_closing_balance['Buy Rate']\n",
    "\n",
    "# Print the result\n",
    "print(yearly_closing_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73de8c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decreasing Volume Over The Time:\n",
    "\n",
    "# Initialize a variable to keep track of the consecutive occurrences\n",
    "consecutive_occurrences = 0\n",
    "\n",
    "# Loop through the 'Closing Balance' column (start from index 1)\n",
    "for i in range(1, len(monthly_closing_balance)):\n",
    "    current_balance = monthly_closing_balance.iloc[i]['Closing Balance']\n",
    "    previous_balance = monthly_closing_balance.iloc[i - 1]['Closing Balance']\n",
    "\n",
    "    # Check if the current balance is 20% less than the previous balance\n",
    "    if current_balance < 0.8 * previous_balance:\n",
    "        consecutive_occurrences += 1\n",
    "    else:\n",
    "        # If the current balance is not 20% less than the previous, reset the consecutive_occurrences\n",
    "        consecutive_occurrences = 0\n",
    "\n",
    "    # Check if consecutive occurrences have reached 3, then break the loop (no need to check further)\n",
    "    if consecutive_occurrences == 3:\n",
    "        break\n",
    "\n",
    "# Determine the corresponding risk percentage\n",
    "if consecutive_occurrences == 1:\n",
    "    risk_percentage = 5\n",
    "elif consecutive_occurrences == 2:\n",
    "    risk_percentage = 10\n",
    "elif consecutive_occurrences >= 3:\n",
    "    risk_percentage = 20\n",
    "else:\n",
    "    risk_percentage = 0  # No consecutive occurrences\n",
    "\n",
    "# Print the result\n",
    "print(\"Risk Percentage:\", risk_percentage, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73c696c",
   "metadata": {},
   "source": [
    "# Fraudulent transactions detection using ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b2da96",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('Data_ML.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ac5c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_ML = pd.read_csv('F:\\Data_ML.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7b01c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694cb43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Encode categorical features using one-hot encoding\n",
    "categorical_features = ['Type', 'Buy Cur.', 'Sell Cur.', 'Exchange']\n",
    "Data_ML_encoded = pd.get_dummies(Data_ML, columns=categorical_features)\n",
    "\n",
    "# Define features and target variable\n",
    "X = Data_ML_encoded.drop(columns=['Fraudulent'])\n",
    "y = Data_ML_encoded['Fraudulent']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Gaussian Naive Bayes model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee5e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('20%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8fcbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Assuming you have already encoded categorical variables and prepared your data\n",
    "# Selecting features\n",
    "feature_columns = ['Buy', 'Sell']\n",
    "X = Data_ML[feature_columns]\n",
    "\n",
    "# Selecting target variable\n",
    "y = Data_ML['Fraudulent']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Impute missing values with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "logreg_model.fit(X_train_imputed, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logreg_model.predict(X_test_imputed)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0b6a35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
